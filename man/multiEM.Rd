% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/functions_EM.R
\name{multiEM}
\alias{multiEM}
\title{EM algorithm}
\usage{
multiEM(
  .D_train = NULL,
  .C_train = NULL,
  .D_test,
  .D_test_out = NULL,
  .n_class = 2,
  .n_cluster = 2,
  .lambda = 0.1,
  .max_iter = 100,
  .alpha = 0.1,
  .labeled_docs = NULL,
  .counter_on = T,
  .active_iter = NULL,
  .maxactive_iter = NULL,
  .fixed_words = NULL,
  .export_all = F,
  .supervise = T,
  .choose_NB_init = FALSE,
  .prev_word_prob = NULL,
  .prev_class_prob = NULL,
  .prev_mu = NA,
  .prev_psi = NA,
  .beta = NULL,
  .binary_metadata_varnames = NA,
  .cont_metadata_varnames = NA
)
}
\arguments{
\item{.D_train}{document term matrix of the labeled documents}

\item{.C_train}{vector of class labels for the labeled documents}

\item{.D_test}{document term matrix of the unlabeled documents}

\item{.D_test_out}{document term matrix for out of sample validation}

\item{.n_class}{number of classes}

\item{.n_cluster}{number of clusters}

\item{.lambda}{vector of document weights}

\item{.max_iter}{maximum number of iteration of the EM algorithm}

\item{.alpha}{the threshold of the convergence. If the increase of the maximand becomes less than alpha,
the iteration stops.}

\item{.labeled_docs}{Optional vector of index values for labeled documents.
Used if `.choose_NB_init == FALSE`}

\item{.counter_on}{boolean object. If \code{counter_on == T}, displays the progress of the EM
algorithm.}

\item{.active_iter}{integer value that tells the EM algorithm which iteration of the active
loop it is in.}

\item{.maxactive_iter}{integer value that tells the EM algorithm the maximum allowed active
iterations.}

\item{.fixed_words}{matrix of fixed words with class probabilities,
where ncol is the number of classes.}

\item{.export_all}{If T, model parameters from each iteration of the EM algorithm are returned.
If F, only model results from the last iteration are returned.}

\item{.supervise}{T if supervised. F is unsupervised.}

\item{.choose_NB_init}{boolean object. By default true, and EM starts with Naive Bayes step.
If false, and if an appropriate `.C_train` is provided, the initial M step is performed with
document class probabilities from both labeled and unlabeled documents, as weighted by the chosen
`.lambda` value.}

\item{.binary_metadata_varnames}{vector of stricts indicating variable names of binary metadata}

\item{.cont_metadata_varnames}{vector of strings indicating variable names of continuous metadata}

\item{.lazy_eval}{boolean object. If \code{lazy_eval == T}, convergence is measured by comparing changes
in log likelihood across model iterations rather than directly computing maximand.}

\item{.class_prob}{required if .supervise == T. Starting value of class probability (logged)}

\item{.word_prob}{required if .supervise == T. Starting value of word probability (logged)}
}
\value{
maximands is a vector of maximands in each iteration. Each element of the vector
contains the log maximand in each step.
pi is a vector of log class probabilities. (length = 2)
eta is a matrix of log word probabilities (nrow = the number of all documents, ncol = 2)
}
\description{
Use EM algorithm to maximize the marginal posterior.
The marginal posterior is the probability of parameters
given both labeled and unlabeled documents and the labels for the labeled documents
}
\details{
The inputs must conform to the following specifications
D_train: a matrix with dimension: the number of labeled documents * the number of unique words
D_test: a matrix with dimension: the number of labeled documents * the number of unique words
The column length of D_train and D_test must be the same. The elements of the D_train, D_test are
integers (the counts of each unique word appeard in each document)
C_train: vector of labels for the labeled documents. The length must be the same as the row length of D_test
}
\references{
Active EM in overleaf
}
